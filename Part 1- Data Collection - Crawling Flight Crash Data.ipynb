{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection - Crawling Flight Crash Data\n",
    "\n",
    "This is the first step in our project. The code below shows a crawler (written using BeautifulSoup, the old school way) that gets raw HTML data from [this](\"http://www.planecrashinfo.com/database.htm\") site, extracts the data from the HTML tables, and writes it to a MongoDB instance running on the same machine. \n",
    "\n",
    "The entire data pipeline is shown below:\n",
    "\n",
    "<img src=\"data_pipeline.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'shivam_gaur'\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Declaring the important 'Global Variables'. \n",
    "* Basically the configuration of our crawl. The start_year and the end year of the crawl could be changed to suit your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The URL \n",
    "rooturl = \"http://www.planecrashinfo.com\"\n",
    "url = \"http://www.planecrashinfo.com/database.htm\"\n",
    "#change start_year to 1920 to crawl the entire dataset\n",
    "start_year = 2014\n",
    "end_year = 2016\n",
    "year_range = range(start_year,end_year+1,1)\n",
    "newurl=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the Mongo DB client running on the same machine. \n",
    "* Must change if the Mongo DB is running on a separate machine. Check MongoDB [docs](https://api.mongodb.org/python/current/api/pymongo/mongo_client.html#pymongo.mongo_client.MongoClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connecting to Mongo instance\n",
    "client = MongoClient()\n",
    "# specify the name of the db in  brackets\n",
    "db = client['aircrashdb']\n",
    "# specify the name of the collection in brackets\n",
    "collection = db['crawled_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to convert month from text to a number [1-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMonth(month):\n",
    "    Months = ['january','february','march','april','may','june','july','august','september','october','november','december']\n",
    "    month = month.lower()\n",
    "    for i,value in enumerate(Months):\n",
    "        if value == month:\n",
    "            return i+1\n",
    "    return 0 # if it is not a valid month string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function that takes <i>url (string)</i> as input and returns <i>BeautifulSoup Object</i> of the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeBeautifulSoupObject(url):\n",
    "    # Use a `Session` instance to customize how `requests` handles making HTTP requests.\n",
    "    session = requests.Session()\n",
    "    # `mount` a custom adapter that retries failed connections for HTTP and HTTPS requests, in this case- 5 times\n",
    "    session.mount(\"http://\", requests.adapters.HTTPAdapter(max_retries=5))\n",
    "    session.mount(\"https://\", requests.adapters.HTTPAdapter(max_retries=5))\n",
    "    source_code = session.get(url=url)\n",
    "    plain_text = source_code.text.encode('utf8')\n",
    "    soup = BeautifulSoup(plain_text, \"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function that pushes a <i> Beautiful Soup Object (HTML table in this case) </i> to a <i>Mongo DB collection</i>\n",
    "* Open [this](http://www.planecrashinfo.com/2015/2015-4.htm) crash record in your browser, and have a look at the HTML source code for reference.\n",
    "* The table_ input basically parses each value according to the format of the key (i.e. Date/location/Aircraft Type/others)\n",
    "* The string.encode('utf-8') is necessary, as the website uses windows-1252 character set- which causes some characters to get messed up if the encoding is not explicitly changed.\n",
    "\n",
    "* This is what the HTML table looks like:\n",
    "<img src='record_example.PNG'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def push_record_to_mongo(table_):\n",
    "    record = {}\n",
    "    table=BeautifulSoup(str(table_[0]))\n",
    "    for tr in table.find_all(\"tr\")[1:]:\n",
    "        tds = tr.find_all(\"td\")\n",
    "        \n",
    "        # encoding the 'value' string to utf-8 and removing any non-breaking space (HTML Character)\n",
    "        tmp_str = tds[1].string.encode('utf-8').replace(\"&nbsp;\", \"\")\n",
    "        value = str(tmp_str) # this is the value- In Column #2 of the HTML table\n",
    "        key = tds[0].string           # this is the key- In Column #1 of the HTML table\n",
    "        \n",
    "        if key == \"Date:\":\n",
    "            dat = str(value).replace(',','').split(' ')\n",
    "            date = datetime.datetime(int(dat[2]),getMonth(dat[0]),int(dat[1]))\n",
    "            record[\"date\"] = date\n",
    "            \n",
    "        elif key == \"Time:\":\n",
    "            if not value == '?':\n",
    "                time = re.sub(\"[^0-9]\", \"\",value)\n",
    "                record[\"time\"] = time\n",
    "            else:\n",
    "                record[\"time\"] = \"NULL\"\n",
    "                \n",
    "        elif key == \"Location:\":\n",
    "            if not value == '?':\n",
    "                record[\"loc\"] = str(value)\n",
    "            else:\n",
    "                record[\"loc\"] = \"NULL\"\n",
    "                \n",
    "        elif key == \"Operator:\":\n",
    "            if not value == '?':\n",
    "                record[\"op\"] = str(value)\n",
    "            else:\n",
    "                record[\"op\"] = \"NULL\"\n",
    "                \n",
    "        elif key == \"Flight#:\":\n",
    "            if not value == '?':\n",
    "                record[\"flight\"] = str(value)\n",
    "            else:\n",
    "                record[\"flight\"] = \"NULL\"\n",
    "                \n",
    "        elif key == \"Route:\":\n",
    "            if not value == '?':\n",
    "                record[\"route\"] = str(value)\n",
    "            else:\n",
    "                record[\"route\"] = \"NULL\"\n",
    "                \n",
    "        elif key == \"Registration:\":\n",
    "            if not value == '?':\n",
    "                record[\"reg\"] = str(value)\n",
    "            else:\n",
    "                record[\"reg\"] = \"NULL\"\n",
    "                \n",
    "        elif key == \"cn / ln:\":\n",
    "            if not value == '?':\n",
    "                record[\"cnln\"] = str(value)\n",
    "            else:\n",
    "                record[\"cnln\"] = \"NULL\"\n",
    "                \n",
    "        elif key == \"Aboard:\":\n",
    "            if not value == '?' :\n",
    "               s = ' '.join(value.split())\n",
    "               aboard_ = s.replace('(','').replace(')','').split(' ')\n",
    "\n",
    "               if aboard_[0] != '?':\n",
    "                   record[\"aboard_total\"] = aboard_[0]\n",
    "               else:\n",
    "                   record[\"aboard_total\"] = 'NULL'\n",
    "\n",
    "               passengers = aboard_[1].replace(\"passengers:\",\"\")\n",
    "               if passengers != '?':\n",
    "                   record[\"aboard_passengers\"] = passengers\n",
    "               else:\n",
    "                   record[\"aboard_passengers\"] = 'NULL'\n",
    "\n",
    "               crew = aboard_[2].replace(\"crew:\",\"\")\n",
    "               if crew != '?':\n",
    "                   record[\"aboard_crew\"] = crew\n",
    "               else:\n",
    "                   record[\"aboard_crew\"] = 'NULL'\n",
    "            else:\n",
    "                record[\"aboard_total\"] = 'NULL'\n",
    "                record[\"aboard_passengers\"] = 'NULL'\n",
    "                record[\"aboard_crew\"] = 'NULL'\n",
    "                \n",
    "        elif key == \"Fatalities:\":\n",
    "            if not value == '?':\n",
    "               s = ' '.join(value.split())\n",
    "               fatalities_ = s.replace('(','').replace(')','').split(' ')\n",
    "\n",
    "               if fatalities_[0] != '?':\n",
    "                   record[\"fatalities_total\"] = fatalities_[0]\n",
    "               else:\n",
    "                   record[\"fatalities_total\"] = 'NULL'\n",
    "\n",
    "               passengers = fatalities_[1].replace(\"passengers:\",\"\")\n",
    "               if passengers != '?':\n",
    "                   record[\"fatalities_passengers\"] = passengers\n",
    "               else:\n",
    "                   record[\"fatalities_passengers\"] = 'NULL'\n",
    "\n",
    "               crew = fatalities_[2].replace(\"crew:\",\"\")\n",
    "               if crew != '?':\n",
    "                   record[\"fatalities_crew\"] = crew\n",
    "               else:\n",
    "                   record[\"fatalities_crew\"] = 'NULL'\n",
    "                    \n",
    "            else:\n",
    "                record[\"aboard_total\"] = 'NULL'\n",
    "                record[\"aboard_passengers\"] = 'NULL'\n",
    "                record[\"aboard_crew\"] = 'NULL'\n",
    "                \n",
    "        elif key == \"Ground:\":\n",
    "            if not value == '?':\n",
    "                record[\"ground\"] = str(value)\n",
    "            else:\n",
    "                record[\"ground\"] = \"NULL\"\n",
    "                \n",
    "        elif key == \"Summary:\":\n",
    "            if not value == '?':\n",
    "                record[\"summary\"] = str(value)\n",
    "            else:\n",
    "                record[\"summary\"] = \"NULL\"\n",
    "                \n",
    "        else:\n",
    "            st1 = ''.join(tds[0].string.split()).lower()\n",
    "            if not value == '?':\n",
    "                record[st1] = str(value)\n",
    "            else:\n",
    "                record[st1] = \"NULL\"\n",
    "                \n",
    "    collection.insert_one(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawler- The Core\n",
    "* <B><U>MAIN IDEA</U>:</B> Leveraging the pattern in the url of the website.\n",
    "    * The hostname of the url remains the same for all the years - i.e.  http://<-hostname-> . \n",
    "    * The path for each year comes after the hostname, i.e. http://<-hostname->/<-year->, where year is a 4 digit year from 1920 to 2016. \n",
    "    * The sub path that actually points us to the record page is http://hostname/ <-year>/<-year>-<-record_number-> , where record_number is a number between 1 and the number of crashes that took place in the corresponding year.\n",
    "     * http://www.planecrashinfo.com/<-year->/<-year->-<-record_number->.htm\n",
    "     \n",
    "     \n",
    "* We will <b>iterate through all the years</b> specified at the beginning of this notebook, and send an appropriate HTTP request by building a url, leveraging the url pattern described above.\n",
    "\n",
    "\n",
    "* The code can be parallelized by using IPython.parallel library, not done for the sake of simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.planecrashinfo.com/2014/2014.htm\n",
      "Time to crawl year 2014-0:00:14.998000\n",
      "http://www.planecrashinfo.com/2015/2015.htm\n",
      "Time to crawl year 2015-0:00:09.765000\n",
      "http://www.planecrashinfo.com/2016/2016.htm\n",
      "Time to crawl year 2016-0:00:02.748000\n",
      "_____________________________________\n",
      "Total program time - 0:00:27.511000\n"
     ]
    }
   ],
   "source": [
    "program_start_time = datetime.datetime.utcnow() # you could uncomment this line if you wish to time the runtime of blocks from here onwards\n",
    "\n",
    "for i in year_range:\n",
    "    year_start = datetime.datetime.utcnow()\n",
    "    # appending the path (year) to the url hostname\n",
    "    newurl = rooturl + \"/\" + str(i) + \"/\" + str(i) + \".htm\"\n",
    "    soup = makeBeautifulSoupObject(newurl)\n",
    "    tables = soup.find_all('table')\n",
    "    print (newurl)\n",
    "\n",
    "    for table in tables:\n",
    "        #finding the no. of records for the given year\n",
    "        number_of_rows = len(table.findAll(lambda tag: tag.name == 'tr' and tag.findParent('table') == table)) \n",
    "        row_range = range(1,number_of_rows,1)\n",
    "        \n",
    "        for j in row_range:\n",
    "            # appending the row number to sub-path of the url, and building the final url that will be used for sending http request\n",
    "            accident_url = newurl.replace(\".htm\",\"\") + \"-\" + str(j) + \".htm\"\n",
    "            web_record = makeBeautifulSoupObject(accident_url)\n",
    "            # removing all the boilerplate html code except the data table\n",
    "            table_ = web_record.find_all('table')\n",
    "            push_record_to_mongo(table_)\n",
    "\n",
    "    print(\"Time to crawl year \" + str(i) + \"-\" + str(datetime.datetime.utcnow()-year_start))\n",
    "\n",
    "program_end_time = datetime.datetime.utcnow()\n",
    "print (\"_____________________________________\")\n",
    "print (\"Total program time - \" + str(program_end_time-program_start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
